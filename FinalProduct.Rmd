---
title: "Applying Machine Learning to Bitcoin Price Prediction"
author: "Tshering Wangchuk & Aaron Salot"
date: 12/08/2021
output: 
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    code_download: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, echo=FALSE, warning=FALSE, include=FALSE}
library(dplyr)
library(readxl)
library(caret)
library(tidyverse)         # for graphing and data cleaning
library(tidymodels)        # for modeling
library(themis)            # for step functions for unbalanced data
library(doParallel)        # for parallel processing
library(stacks)            # for stacking models
library(naniar)            # for examining missing values (NAs)
library(lubridate)         # for date manipulation
library(moderndive)        # for King County housing data
library(vip)               # for variable importance plots
library(patchwork)         # for combining plots nicely
library(DALEX)
library(DALEXtra)
library(rpart)
library(ggthemes)
library(SLICER)
theme_set(theme_minimal()) # Lisa's favorite theme
```

# Introduction

Bitcoin, and other cryptocurrencies, have been present for over a decade, and have become increasingly prevalent in the global economic system. Bitcoin, the first and most widely used cryptocurrency, is used as a store of value, tradable asset, and a form of currency. This analysis aims to take advantage of the open-source blockchain network behind Bitcoin, and our goal is to understand the various factors that influence the price movement of Bitcoin. 


Bitcoin popularized blockchain technology, and Satoshi Nakamoto used it to solve the Byzanztine's General Problem and the double-spending problem without the need of a central authority. It is also the fastest growing asset class to have reached close to $2-3 trillion in market capitalization in over a decade. Given the recent technological adoption as seen with Tesla, Microstrategy & El Salvador's government, we are particularly interested to examine the price movement of Bitcoin by looking at certain variables that are publically accessible through Bitcoin's public ledger.


# Data Sources

We used three different data sources: CoinMetrics, Glassnodes & FRED. We collected an overall of 162 variables with over 4000 observations; however, after basic explanatory analysis and cleaning, we ended up with 88 variables and 2,100 observations. CoinMetrics was the largest bulk of our data, where we used their public API to extract daily data from 2010 to present (November, 2021). We also secured a Glassnodes membership that gave access to daily changes in select variables not present in the CoinMetrics API. Taking from the previous literature review, we also decided to incorporate certain variables that have been examined in previous papers - CPI, Gold Price, Nasdaq & Bitcoin Google Search trends. 

# Global Interpretation of ML Models

```{r, echo=FALSE}
ADS_Project_11_29_2021_v8 <- read_excel("ADS_Project - 11.29.2021.v8.xlsx")

Master <- ADS_Project_11_29_2021_v8 %>%
select(-c(`Last Calculated EOD metrics (time, in seconds)`, `Block Count`, `Block Size (mean, in bytes)`, `Block Weight, (mean`, `Capitalization of current supply, MVRV`, `Capitalization of free float, MVRV`, `Difficulty, Last Block`, `Difficulty, Mean Block`, `Mean Transaction Fee per Byte of all blocks, native units`, `Mean Transaction Fee per Byte, native units`, `Median Transaction Fee, native units`, `Median Fee per Transacation, USD`, `Addresses balance greater than 0.001 native units`, `Addresses balance greater than 0.01 native units`, `Addresses balance greater than 0.1 native units`,`Addresses balance greater than 100 native units`, `Addresses balance greater than 100K native units`, `Addresses balance greater than 10 native units`, `Addresses balance greater than 10K native units`, `Addresses balance greater than 1 native units`, `Addresses balance greater than 1K native units`, `Addresses balance greater than 1M native units`, `Addresses balance greater than 1in100K`, `Addresses balance greater than 1in100M`, `Addresses balance greater than 1in10B`, `Addresses balance greater than 1in10K`, `Addresses balance greater than 1in10K`, `Addresses balance greater than 1in10M`, `Addresses balance greater than 1in1B`, `Addresses balance greater than 1in1K`, `Addressesbalance greater than 1in1M`, `Total Fees, native units`, `Flow to exchanges, native units`, `Flow out exchanges, native units`, `Gas Limit Block`, `Gas Limit, transaction`, `Gas Used, transaction`, `Hash Rate Mean, 30d`, `Issuance, native units`, `Issuance, percent annualized`, `Issuance,  percent daily`, `Issuance Total, native units`,`NVT, adjusted, 90d MA`, `NVT, adjusted, free float,  90d MA`, `ROI, 1y (%)`, `Revenue, per hash unit (Native Currency)`, `Revenue Daily, per hash unit/second (Native Currency)`, `Miner Rev (Native Currency)`, `Supply, 10y Active`, `Supply, 5yr Active`, `Supply, 4yr Active`, `Supply, 3yr Active`, `Supply, 1yr Active Trailing (%)`, `Supply, in addresses (<0.001, native currency)`, `Supply, in addresses (<0.01M, native currency)`, `Supply, in addresses (<0.1, native currency)`, `Supply, in addresses (<1, native currency)`, `Supply, in addresses (<10, native currency)`, `Supply, in addresses (<100, native currency)`, `Supply, in addresses (<100K, native currency)`, `Supply, in addresses (<10K, native currency)`, `Supply, in addresses (<1K, native currency)`, `Supply, in addresses (<1M, native currency)`, `Supply, Miner address with 1 mining entity (native currency)`, `Supply, All Miners (native currency)`, `Transactions, adjusted transfer value (native currency)`, `Transactions, mean transfer value (native currency)`, `Transactions, median transfer value (native currency)`, `Transactions, mean transfer value ($)`, `Transactions, median transfer value (native currency)`, `Velocity, 1yr current supply`, `Volatility, 180d daily returns`, `Volatility, 30d daily returns`, `Price, BTC`, `Price, ($)`, `Transactions, median transfer value ($)`))

Master <- Master %>% select(-c(`Gas limit Mean, transaction`, `Hash Rate, mean`, `Issuance, in USD`, `Issuance Total, in USD`, `ROI, 30D (%)`, `Revenue Daily, per hash unit/second (USD)`, `Revenue, per hash unit ($)`, `Supply Equality Ratio`, `Supply, 180D Active`, `Supply, 1yr Active`, `Supply, 2y Active`, `Supply, 1yr Active`, `Supply, Miner address with 1 mining entity ($)`, `Transactions, count`,`Transactions, count (per second)`, `Transactions, adjusted transfer value ($)`, `Coin_Days_Destroyed`, `Balance_Exchanges_(%)`, `Total_Exchange_Inflow_Volume`, `Supply, 30D Active`, `Supply, 7D Active`, `Supply, 90D Active`, `Supply, address balance (<1in10K)`, `Supply, address balance (<1in10M)`, `Supply, address balance (<1in10B)`, `Supply, address balance (<1in10K)`, `Supply, address balance (<1in1B)`, `Supply, address balance (<1in1K)`, `Supply, address balance (<1in1M)`, `Supply, in addresses (<$1)`, `Supply, in addresses (<$10)`, `Supply, in addresses (<$100)`, `Supply, in addresses (<$100K)`, `Supply, in addresses (<$10K)`, `Supply, in addresses (<$10M)`, `Supply, in addresses (<$1K)`, `Supply, held by top 1% addresses`, `Supply, 10yr expected supply`, `Supply, free float`, `Supply, All Miners ($)`, `Supply, Miner address with 1 mining entity ($)`, `Transactions, count`, `Transactions, adjusted transfer value ($)`, `Coin_Days_Destroyed`, `CPI_(%)`))

Master <- Master %>% select(-c(`All Addresses balance`, `Addresses balance greater than $100`, `Addresses balance greater than $10`, `Addresses balance greater than $1`, `Capitalization of active native units supply, in USD`, `Capitalization of free float, in USD`, `Capitalization realized, USD`, `NVT, adjusted, free float`, `Miner Rev ($)`, `Supply, current`, `Flow transfers exchanges`, `Supply, address balance (<1in100M)`, `Supply, in addresses (<$1M)`, `Transactions, transfer count`, `NUPL`, `rHODL`, `Addresses Active Count`,`Addresses balance greater than $10K`, `Addresses balance greater than $100K`, `Addresses balance greater than $1K`, `Addresses balance greater than $1M`, `Block, weight, total`))
```

```{r, include=FALSE}
 Master <- Master %>%
           mutate(Date = ymd(Date)) %>% 
           mutate(Date_num = as.numeric(Date)) %>%
           mutate(lag1day = lag(Price, 1, order_by = Date),
                  lag7day = lag(Price, 7, order_by = Date)) %>%
           replace_na(list(lag1day = 0, lag7day = 0)) %>% 
           mutate(Daily_avg = (Price + lag1day)/2,
                  Weekly_avg = (Price + lag7day)/7) %>%
           select(-c(CPI, `BTC(%)`, `NDQ(%)`, `Gold(%)`, BTC_Searches, `BTCS(%)`))

Master <- Master %>% mutate(Date = ymd(Date)) %>% 
           mutate(Date_num = as.numeric(Date)) %>%
           mutate(PriceDirection = ifelse(Price > lag1day, yes = 1, no = 0)) %>%
           mutate(PriceDirection = as.factor(PriceDirection)) 
        
```


```{r, include=FALSE}
set.seed(456)
Master_Split <- initial_split(Master, prop = 0.75)

Master_Training <- training(Master_Split)
Master_Testing <- testing(Master_Split)
```

```{r, include=FALSE}
# Lasso recipe

lasso_recipe <- recipe(PriceDirection ~ .,
                       data = Master_Training) %>%
                step_rm(Date, Weekly_avg, Daily_avg, lag7day, lag1day, `Network distribution factor`, `Capitalization of Current Supply, in USD`, `Supply, held by top 10% addresses`) %>%
                step_mutate_at(all_numeric(), -all_outcomes(), fn= ~ as.numeric(.)) %>%
                step_dummy(all_nominal(), -all_outcomes()) %>%
                update_role(Date_num, new_role = "ID") %>%
                step_zv(all_predictors()) %>%
                step_normalize(all_predictors(), -all_nominal())

lasso_recipe %>% prep() %>% juice()

# Lasso tune 

lasso_mod <- logistic_reg(mixture = 1) %>%
             set_engine("glmnet") %>% 
             set_args(penalty = tune()) %>% 
             set_mode("classification")

lasso_wf <- workflow() %>%
            add_recipe(lasso_recipe) %>%
            add_model(lasso_mod) 

set.seed(494)
btc_cv <- vfold_cv(Master_Training,
                   v = 10)

penalty_grid <- grid_regular(penalty(),
                             levels = 10)

ctrl_grid <- control_stack_resamples()

metric <- metric_set(accuracy)

lasso_tune <- lasso_wf %>%
              tune_grid(resamples = btc_cv,
                        grid = penalty_grid,
                        control = ctrl_grid)

lasso_tune %>% collect_metrics()
```

```{r, include=FALSE}
best_param <- lasso_tune %>%
              select_best(metric = "accuracy")
best_param

final_lasso <- lasso_wf %>% finalize_workflow(best_param) %>%
               fit(data = Master_Training)
```


```{r, include=FALSE}
set.seed(456)
rf_recipe <- recipe(PriceDirection ~.,
                    data = Master_Training) %>%
             step_mutate_at(all_numeric(), fn = ~as.numeric(.)) %>%
             step_rm(Weekly_avg, Daily_avg, lag7day, lag1day, `Network distribution factor`, `Capitalization of Current Supply, in USD`, `Supply, held by top 10% addresses`) 

rf_recipe %>% prep() %>% juice()

rf_model <- rand_forest(mtry = tune(),
                        min_n = tune(),
                        trees = 10) %>%
            set_mode("classification") %>%
            set_engine("ranger")

rf_workflow <- workflow() %>%
               add_recipe(rf_recipe) %>%
               add_model(rf_model)

rf_penalty_grid <- grid_regular(finalize(mtry(),
                                Master_Training %>%
                                select(-PriceDirection)),
                                min_n(),
                                levels = 2)

rf_tune <- rf_workflow %>%
           tune_grid(resamples = btc_cv,
                     grid = rf_penalty_grid,
                     control = control_stack_grid())

rf_tune %>% collect_metrics()


```

```{r, warning=FALSE, include=FALSE}
best_param_rf <- rf_tune %>%
              select_best(metric = "accuracy")
best_param_rf

rf_final <- rf_workflow %>% finalize_workflow(best_param_rf) %>%
              fit(Master_Training)
```

```{r, include=FALSE}
set.seed(456)

tree_model <-
  decision_tree() %>%
  set_mode("classification") %>%
  set_engine("rpart")

tree_workflow <-
  workflow() %>%
  add_recipe(rf_recipe) %>%  
  add_model(tree_model)

tree_fit <-
  tree_workflow %>%
  fit_resamples(btc_cv,
                control = control_stack_resamples()
  )

collect_metrics(tree_fit)
```

```{r, include=FALSE}
best_param_tree <- tree_fit %>%
              select_best(metric = "accuracy")
best_param_tree

tree_final <- tree_workflow %>% finalize_workflow(best_param_rf) %>%
              fit(data = Master_Training)
```

## Model Performance

```{r}
lasso_explain <- 
  explain_tidymodels(
    model = final_lasso,
    data = Master_Training %>% select(-PriceDirection),
    y = Master_Training %>%
      mutate(Price_num = as.integer(PriceDirection)) %>%
      pull(Price_num),
    label = "Lasso"
  )

rf_explain <- 
  explain_tidymodels(
    model = rf_final,
    data = Master_Training %>% select(-PriceDirection),
    y = Master_Training %>%
      mutate(Price_num = as.integer(PriceDirection)) %>%
      pull(Price_num),
    label = "rf"
  )

tree_explain <- 
  explain_tidymodels(
    model = tree_final,
    data = Master_Training %>% select(-PriceDirection),
    y = Master_Training %>%
      mutate(Price_num = as.integer(PriceDirection)) %>%
      pull(Price_num),
    label = "tree"
  )

lasso_model_performance <- model_performance(lasso_explain)
rf_model_performance <- model_performance(rf_explain)
tree_performance <- model_performance(tree_explain)
```

```{r}
plot(lasso_model_performance, rf_model_performance, tree_performance, geom = "boxplot")
plot(lasso_model_performance, rf_model_performance, tree_performance, geom = "histogram")
```

## Variable Importance

```{r}
set.seed(456)

lasso_var_imp <-
  model_parts(
    lasso_explain
  )

plot(lasso_var_imp)
```

```{r}
set.seed(456)

rf_var_imp <-
  model_parts(
    rf_explain
  )

plot(rf_var_imp)
```

```{r}
set.seed(456)

tree_var_imp <-
  model_parts(
    tree_explain
  )

plot(tree_var_imp)
```

<br> We can see that the LASSO model has the most amount of variables of importance, while Random Forest and the Tree Model have 6 variables of importance. This implies that the variables on the bottom of the graph, the ones with greater importance, play a greater role in increasing the performance of the model - when accounting for the other variables in the equation. The length of the bar indicates how much the RMSE increases when that variable is permuted. 

## Ceteris-Paribus Profile

```{r}
rf_cpp <- function(explainer,  obs, var){
  cprofile <- predict_profile(explainer = explainer, new_observation = obs, variables = var)
  cprofile %>% 
    filter(`_vname_` %in% c(var)) %>%
    ggplot(aes_string(x = var,
                      y = "`_yhat_`")) + geom_line()
}


obs23 <- Master_Training %>%
    slice(23)

rf_cpp(rf_explain, obs23, "SOPR")
```

## Partial Dependence Plots

```{r}
set.seed(253)

rf_partial <- model_profile(explainer = rf_explain)

plot(rf_partial,
     variables = "SOPR",
     geom = "profiles")
```

<br> A partial depending plot is created by averaging the CP profiles for a sample of observations. It is the blue line seen in the graph above, and we can observe that overall the changes to the value of the longitutde increase the effect on the price direction to an extent, however, after a certain point, have a reduce impact in being able to predict the price price direction. We decided to go ahead with random forest for the partial dependence plots since LASSO would produce inclined parallel lines due to it's additive nature. 

# Local Interpretation of ML models

<br> Local model interpretation helps us understand the impact of variables on individual observatons. Throughout this section, we will focus on the random forest model since it was the one with the highest accuracy. 

## Local Interpretable Model-agnostic Explanations (LIME)

```{r}
set.seed(456)

model_type.dalex_explainer <- DALEXtra::model_type.dalex_explainer
predict_model.dalex_explainer <- DALEXtra::predict_model.dalex_explainer

lime_rf <- predict_surrogate(explainer = rf_explain,
                             new_observation = obs23 %>% select(-PriceDirection),
                             n_features = 5,
                             n_permutations = 1000,
                             type = "lime")

lime_rf %>% select(model_r2, model_prediction, prediction) %>% distinct()

plot(lime_rf) +
  labs(x = "Variable")
```

<br> The table above shows that the predicted value from the original random forest (prediction) model is: 0.9, while the overall model performance is 0.0282, and the prediction from the local model is 0.4796. The bars in the plot above are ordered by weight, and indicate which variables are more important in the local model. 


## Shapley Additive Explanations (SHAP)

```{r}
rf_shap <- predict_parts(explainer = rf_explain,
                         new_observation = obs23,
                         type = "shap",
                         B = 10)

plot(rf_shap)
```

<br> The idea behind the SHAP is to change the order in which we consider the variables in the break-down plots. The graph above shows the average contribution of each variable's value to the predictive response for this observation. For example, the SOPR of 1.005 contributes to an additional ~0.12 to the predicted prive direction for this observation on average. The boxplots show the variation across permutations of the variables. The larger the variation of the boxplot, and the ones that lie across positive and negative values, the less confident we can be regarding it's effect on the predictor. In this observative, we can be less confident about the effect of SOPR, and Flow to exchanges, SUpply, held by top 100 addresses, adjusted dormancy flow, among a few others. 

# Conclusion

<br> Both methods indicate how changes in the values of the variables for an observation can affect the predicted outcome. While some variables overlap between both approaches, the SHAP method includes more variables overall and is less reliable due to the fact that many variables encompass positive and negative contributions. Due to the volatility of this market and the variables we're looking at, the duration / obervation being examined plays a very crucial role in affecting the results of each variable. For example, bull-market tendencies of investors are different from bear-market tendencies. In other words, if Bitcoin is witnessing a bull-market, the behavior of the investors, which is then reflected on blockchain and our variables, changes; however, in a bear market, the inherent behavior of investors would be different. That might explain why the importance of some of these variables differ based on the specific observation. 


# Limitations

<br> One of the limitations of our project is that we cannot determine the strength of Bitcoinâ€™s price movement in each direction. While our accuracy of 58% will allow an individual to make successful investments more than unsuccessful ones, we cannot quantify the strength of the price movement. If we were to replicate this study, we would look into creating PriceDirection as a categorical variable instead of a binary - this way we would be able to identify when the select variables cause a strong bitcoin price movement vis-a-vis a weak price movement. 

<br> Another potential limitation is the rate of maturation of this market. Given that cryptocurrencies and Bitcoin have only existed for over a decade, there are certain variables and trends that affect the price movement over time - due to many structural changes in the market (i.e. greater access to crypto investments, the size of the market cycle, the saturation of the crypto market). For example, the google trend searches of Bitcoin in 2012-2015 played a strong role in determining the price of Bitcoin (Kristoufek, 2013), however that variable did not play as significant of a role in the recent years. Therefore, even though we identified select variables, it would be imperative to replicate this study years from now to reassess their importance as the market matures. 


